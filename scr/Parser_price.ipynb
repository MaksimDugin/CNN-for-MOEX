{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4fa39cda",
   "metadata": {},
   "source": [
    "Python      3.12.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130174cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip freeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2a7ffd-1029-4b68-8bc4-2cc6ae12b796",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests as rq\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import plotly.express as px\n",
    "from pathlib import Path\n",
    "import plotly.graph_objects as go\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c90ba10",
   "metadata": {},
   "source": [
    "# Преобразование данных мосбиржи"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdbfa42f",
   "metadata": {},
   "source": [
    "## Пример получения данных по акции Лукойл с помощью API мосбиржи"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb93351b",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = f\"https://iss.moex.com/iss/engines/stock/markets/shares/securities/LKOH/candles.json?from=2024-04-01\"\n",
    "\n",
    "# Отправляем GET-запрос по указанной ссылке\n",
    "response = rq.get(url)\n",
    "\n",
    "# Проверяем статус ответа\n",
    "if response.status_code == 200:\n",
    "    # Загружаем данные из ответа в переменную data в случае успеха\n",
    "    data = response.json()\n",
    "else:\n",
    "    print(\"Ошибка при получении данных\")\n",
    "    \n",
    "# Выбираем датасет с ценами    \n",
    "columns = response.json()[\"candles\"]['columns']\n",
    "data = response.json()[\"candles\"][\"data\"]\n",
    "\n",
    "df = pd.DataFrame(data, columns=columns)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e8fe89-0798-4fae-aa55-ce5d28dec98c",
   "metadata": {},
   "source": [
    "## Парсинг данных цен"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "202ef35d",
   "metadata": {},
   "source": [
    "### Сначала составим список акций, которые будут участвовать в нашем портфеле"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca2a74de",
   "metadata": {},
   "source": [
    "Выберем акции с market cap > 1e+9 рублей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84f91d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://iss.moex.com/iss/engines/stock/markets/shares/securities.json\"\n",
    "\n",
    "# Отправляем GET-запрос по указанной ссылке\n",
    "response = rq.get(url)\n",
    "\n",
    "# Проверяем статус ответа\n",
    "if response.status_code == 200:\n",
    "    # Загружаем данные из ответа в переменную data в случае успеха\n",
    "    data = response.json()\n",
    "else:\n",
    "    print(\"Ошибка при получении данных\")\n",
    "    \n",
    "columns = response.json()[\"securities\"]['columns']\n",
    "data = response.json()[\"securities\"][\"data\"]\n",
    "\n",
    "df = pd.DataFrame(data, columns=columns)\n",
    "df = df[df[\"BOARDID\"]==\"TQBR\"]\n",
    "df = df[df[\"ISSUESIZE\"]*df[\"PREVWAPRICE\"]>1e+9].reset_index().drop('index', axis=1)\n",
    "ticker_names = df[\"SECID\"].values.tolist()\n",
    "ticker_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd04d11",
   "metadata": {},
   "source": [
    "Выберем те, которые появлись позже 17.06.2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4931442f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers = []\n",
    "date_today = (datetime.now()-timedelta(days=1)).strftime(\"%Y-%m-%d\")\n",
    "\n",
    "\n",
    "for ticker in ticker_names:\n",
    "    url = f\"https://iss.moex.com/iss/engines/stock/markets/shares/securities/{ticker}/candles.json?from={date_today}\"\n",
    "\n",
    "    # Отправляем GET-запрос по указанной ссылке\n",
    "    response = rq.get(url)\n",
    "\n",
    "    # Проверяем статус ответа\n",
    "    if response.status_code == 200:\n",
    "        # Загружаем данные из ответа в переменную data в случае успеха\n",
    "        data = response.json()\n",
    "        \n",
    "        columns = data[\"candles\"]['columns']\n",
    "        data = data[\"candles\"][\"data\"]\n",
    "\n",
    "        df = pd.DataFrame(data, columns=columns)\n",
    "        #print(df)\n",
    "\n",
    "        if not df.empty:\n",
    "            url = f\"https://iss.moex.com/iss/engines/stock/markets/shares/securities/{ticker}/candles.json?from={datetime(2023, 6, 1).strftime(\"%Y-%m-%d\")}\"\n",
    "\n",
    "            # Отправляем GET-запрос по указанной ссылке\n",
    "            response = rq.get(url)\n",
    "\n",
    "            # Проверяем статус ответа\n",
    "            if response.status_code == 200:\n",
    "                # Загружаем данные из ответа в переменную data в случае успеха\n",
    "                data = response.json()\n",
    "                \n",
    "                columns = data[\"candles\"]['columns']\n",
    "                data = data[\"candles\"][\"data\"]\n",
    "\n",
    "                df = pd.DataFrame(data, columns=columns)\n",
    "                #print(df)\n",
    "\n",
    "                # Преобразуем столбец \"begin\" в формат datetime\n",
    "                df['begin'] = pd.to_datetime(df['begin'])\n",
    "                min_begin_date = df['begin'].min()\n",
    "                if min_begin_date <= datetime(2023, 6, 1, 9 , 50, 0):\n",
    "                    tickers.extend([ticker])\n",
    "    else:\n",
    "        print(f\"Ошибка при получении данных для акции {ticker}\")\n",
    "\n",
    "print(tickers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b7bc1a",
   "metadata": {},
   "source": [
    "### Теперь перейдём непосредственно к пасрингу"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e4b4d0-c4a4-440e-af0f-d9fb3bcaceea",
   "metadata": {},
   "source": [
    "Сначала мы создаём массив, который содержить все даты, за которые мы хотим получить данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0d48f5-16bd-4ba9-9b74-5675afafd480",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Дата такая, потому что начиная с неё появляется информация\n",
    "start_date = datetime(2023, 6, 1)\n",
    "end_date = datetime.now()\n",
    "\n",
    "current_date = start_date\n",
    "array_date = []\n",
    "while current_date <= end_date:\n",
    "    array_date += [current_date.strftime(\"%Y-%m-%d\")]\n",
    "    current_date += timedelta(days=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "859d4d37-ee62-457a-80e0-e39f13a36002",
   "metadata": {},
   "source": [
    "Тут мы формируем массив из дней, а затем, если сервер работает хорошо, то возвращаем данные за весь промежуток от 8-го декабря 2011 года до сегодняшнего дня. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e33f9112-9f36-4685-9a4c-d9a69e343b23",
   "metadata": {},
   "source": [
    "Если сервер перестаёт отвечать, тогда полученные данные мы собираем в файл и при повторном запуске программа проверить наши файлы и начнёт с последнего записанного дня."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b4c28a5-2bf3-448d-8344-ca2987603012",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-01T19:42:06.545174Z",
     "iopub.status.busy": "2023-12-01T19:42:06.544183Z",
     "iopub.status.idle": "2023-12-01T19:42:06.567181Z",
     "shell.execute_reply": "2023-12-01T19:42:06.566182Z",
     "shell.execute_reply.started": "2023-12-01T19:42:06.545174Z"
    }
   },
   "source": [
    "В качестве отладки печатается дата дня, который мы сейчас получаем. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84838e65-1b77-4d33-b6a5-afbd54555f22",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def add_new_day(date_today: str, ticker: str): \n",
    "    url = f\"https://iss.moex.com/iss/engines/stock/markets/shares/securities/{ticker}/candles.json?from={date_today}&till={date_today}\" \n",
    "\n",
    "    while True: \n",
    "        try: \n",
    "            response = rq.get(url) \n",
    "        except Exception as e: \n",
    "            # Обработка других исключений \n",
    "            print(f\"Произошла ошибка: {e}\") \n",
    "        else: \n",
    "            break \n",
    "    \n",
    "    # Проверяем статус ответа \n",
    "    if response.status_code != 200: \n",
    "        print(\"Ошибка при получении данных\") \n",
    "        add_new_day(date_today, ticker) \n",
    " \n",
    "    # Создание датафрейма\n",
    "    df_for_add = pd.DataFrame(response.json()[\"candles\"][\"data\"], columns=response.json()[\"candles\"]['columns']) \n",
    "    df_for_add.reset_index().drop('index', axis=1) \n",
    "    return df_for_add \n",
    " \n",
    "def process_ticker(ticker: str):\n",
    "    # Проверяем существование файла '{ticker}_full_date_price.csv'\n",
    "    if Path(f'{ticker}_full_date_price.csv').exists():\n",
    "        print(f\"Файл '{ticker}_full_date_price.csv' существует.\")\n",
    "\n",
    "        # Загружаем данные из файла\n",
    "        df = pd.read_csv(f'{ticker}_full_date_price.csv')\n",
    "\n",
    "        # Преобразование столбца 'begin' в формат даты\n",
    "        df['begin'] = pd.to_datetime(df['begin'])\n",
    "\n",
    "        # Находим индекс последней даты с данными\n",
    "        last_date_str = df['begin'].iloc[-1].strftime('%Y-%m-%d')\n",
    "        \n",
    "        if last_date_str in array_date:\n",
    "            df_array = [df]\n",
    "            # Добавляем данные для каждого дня из списка array_date, начиная со следующего дня после date_tomorrow\n",
    "            for date in array_date[array_date.index(last_date_str):]:\n",
    "                df_array += [add_new_day(date, ticker)]\n",
    "\n",
    "            # Объединяем все DataFrame из df_array и сбрасываем индексы\n",
    "            df = pd.concat(df_array).reset_index(drop=True)\n",
    "\n",
    "            df = df.drop_duplicates()\n",
    "\n",
    "            # Сохраняем обновленные данные в файл\n",
    "            df.to_csv(f'{ticker}_full_date_price.csv', sep=',', index=False, encoding='utf-8')\n",
    "    else:\n",
    "        print(f\"Файл '{ticker}_full_date_price.csv' не существует.\")\n",
    "        df_array = []\n",
    "\n",
    "        # Добавляем данные для каждого дня из списка array_date\n",
    "        for date in array_date:\n",
    "            df_array += [add_new_day(date, ticker)]\n",
    "            # print(date)\n",
    "\n",
    "        # Объединяем все DataFrame из df_array и сбрасываем индексы\n",
    "        df = pd.concat(df_array).reset_index().drop('index', axis=1)\n",
    "\n",
    "        # Сохраняем данные в файл '{ticker}_full_date_price.csv'\n",
    "        filename = f'{ticker}_full_date_price.csv'\n",
    "        df.to_csv(filename, sep=',', index=False, encoding='utf-8')\n",
    "\n",
    "\n",
    "# При работе с несколькими акциями используется многопоточность\n",
    "with ThreadPoolExecutor() as executor: \n",
    "    executor.map(process_ticker, tickers)\n",
    "#process_ticker()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24226896",
   "metadata": {},
   "source": [
    "## Работа с данными"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace19530",
   "metadata": {},
   "source": [
    "### Нарисуем график цен всех акций"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb5ef639",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаем пустую фигуру\n",
    "fig = go.Figure()\n",
    "\n",
    "# Проходимся по каждому тикеру\n",
    "for ticker in tickers:\n",
    "    # Загрузка данных из CSV файла в DataFrame\n",
    "    df = pd.read_csv(f'{ticker}_full_date_price.csv')\n",
    "\n",
    "    # Преобразование столбца 'begin' в формат даты\n",
    "    df['begin'] = pd.to_datetime(df['begin'])\n",
    "    \n",
    "    # Находим начальное значение цены\n",
    "    initial_price = df['close'].iloc[0]\n",
    "\n",
    "    # Нормируем цены\n",
    "    normalized_close = df['close'] / initial_price\n",
    "\n",
    "    # Добавляем нормированный график цены для текущего тикера\n",
    "    fig.add_trace(go.Scatter(x=df['begin'], y=normalized_close, mode='lines', name=f'{ticker}'))\n",
    "\n",
    "# Настраиваем макет графика\n",
    "fig.update_layout(title='Нормированные графики цен для нескольких тикеров', xaxis_title='begin', yaxis_title='Normalized Close Price')\n",
    "\n",
    "# Отображаем рисунок\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8a383d",
   "metadata": {},
   "source": [
    "### Разобьём данные на 9 месяцев (тренировочные данные), 10-ый месяц (тестовые данные)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5369f166",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_data = []\n",
    "start_date = datetime(2023, 6, 1)\n",
    "min_length_train = float('inf')\n",
    "min_length_test =  float('inf') # Инициализируем минимальную длину как бесконечность\n",
    "\n",
    "# Загрузка данных для каждого тикера и создание групп данных\n",
    "for ticker in tickers:\n",
    "    # Загрузка данных из CSV файла\n",
    "    df = pd.read_csv(f'{ticker}_full_date_price.csv')\n",
    "\n",
    "    # Преобразование столбца 'begin' в формат даты\n",
    "    df['begin'] = pd.to_datetime(df['begin'])\n",
    "\n",
    "    # Определяем дату окончания тренировочного периода (9 месяцев)\n",
    "    end_train_date = start_date + pd.DateOffset(months=9)\n",
    "    \n",
    "    # Определяем дату окончания тестового периода (1 месяц после окончания тренировочного периода)\n",
    "    end_test_date = end_train_date + pd.DateOffset(months=1)\n",
    "    \n",
    "    # Выбираем данные для тренировочного набора\n",
    "    train_data = df[(df['begin'] >= start_date) & (df['begin'] < end_train_date)]\n",
    "    \n",
    "    # Выбираем данные для тестового набора\n",
    "    test_data = df[(df['begin'] >= end_train_date) & (df['begin'] < end_test_date)]\n",
    "    \n",
    "    # Обновляем минимальную длину\n",
    "    min_length_train = min(min_length_train, len(train_data))\n",
    "    min_length_test = min(min_length_test, len(test_data))\n",
    "\n",
    "    # Добавляем тренировочные и тестовые данные в список\n",
    "    grouped_data.append((train_data, test_data))\n",
    "    \n",
    "# Обрезаем данные до минимальной длины для каждой группы\n",
    "for i, (train_data, test_data) in enumerate(grouped_data):\n",
    "    grouped_data[i] = (train_data[:min_length_train], test_data[:min_length_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa1bfc5",
   "metadata": {},
   "source": [
    "### Преобразуем данные к нужному виду и запишем их в свой файл"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df390a84",
   "metadata": {},
   "source": [
    "Для данных о цене закрытия и объёме"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d95506c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Определяем функцию generate_thresholds для создания пороговых значений\n",
    "def generate_thresholds(data):\n",
    "    min_val = np.min(data)\n",
    "    max_val = np.max(data)\n",
    "    thresholds = np.array([])\n",
    "    for i in range(15):\n",
    "        thresholds = np.append(thresholds, min_val + (i + 1) * (max_val - min_val) / 15)\n",
    "    return thresholds\n",
    "\n",
    "# Создаём матрицу из 0 и 1\n",
    "def generate_matrix(data):\n",
    "    threshold_matrix = np.zeros((15, 32))\n",
    "    thresholds = generate_thresholds(data)\n",
    "\n",
    "    for i, value in enumerate(data):\n",
    "        index = np.searchsorted(thresholds, value)\n",
    "        if index < 15:  # Первые 15 строк - данные о цене закрытия\n",
    "            threshold_matrix[14-index, i] = 1\n",
    "\n",
    "    return threshold_matrix\n",
    "\n",
    "# Определяем функцию generate_sequence для создания последовательности матриц\n",
    "def generate_sequence(price_data, volume_data):\n",
    "    matrix_sequence = []\n",
    "    for i in range(len(price_data)-31):\n",
    "        price_matrix = generate_matrix(price_data[i:i+32])\n",
    "        volume_matrix = generate_matrix(volume_data[i:i+32])\n",
    "        matrix_sequence.append(price_matrix)\n",
    "        matrix_sequence.append(np.zeros((2, 32)))  # Добавляем две пустые строки\n",
    "        matrix_sequence.append(volume_matrix)\n",
    "    return matrix_sequence\n",
    "\n",
    "# Запись матриц в файл\n",
    "def write_data_X(train_or_test, matrices):\n",
    "    name = 'test' if train_or_test % 2 == 1 else 'train'  # Определение train или test     \n",
    "\n",
    "    mode = 'a' if Path(f'input_{name}_X.txt').exists() else 'w'\n",
    "\n",
    "    with open(f'input_{name}_X.txt', mode) as f:\n",
    "        for i, matrix in enumerate(matrices):\n",
    "            if i >= (len(matrices) - 3):\n",
    "                pass\n",
    "            else:\n",
    "                for row in matrix:\n",
    "                    row_str = ' '.join(map(str, row.astype(int)))  # Преобразование к целочисленному типу\n",
    "                    f.write(row_str + '\\n')\n",
    "                if i % 3 == 2:  # Добавляем 'E' после каждой третьей матрицы\n",
    "                    f.write('E\\n')\n",
    "\n",
    "        # Заменяем последнюю строку на строку с символом 'F'\n",
    "        f.seek(0, 2)  # Переходим в конец файла\n",
    "        f.seek(f.tell() - 3, 0)  # Переходим к последнему символу перед EOF\n",
    "        f.write('F\\n')  # Заменяем 'E' на 'F'\n",
    "\n",
    "# Определяем функцию для записи данных в файл для одной группы\n",
    "def process_group_X(group):\n",
    "    # Находим минимальную длину данных среди всех групп\n",
    "    for i in range(2):\n",
    "        price_data = group[i]['close']\n",
    "        volume_data = group[i]['volume']\n",
    "\n",
    "        # Создание последовательности матриц\n",
    "        matrices = generate_sequence(price_data, volume_data)\n",
    "\n",
    "        # Запись данных в файл\n",
    "        write_data_X(i, matrices)\n",
    "\n",
    "for group in tqdm(grouped_data, desc='Processing groups'):\n",
    "    process_group_X(group)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f4ac90a",
   "metadata": {},
   "source": [
    "Для данных о разнице цены"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379eeea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Запись изменений цены в файл\n",
    "def write_data_Y(train_or_test, diff_data):\n",
    "    name = 'test' if train_or_test % 2 == 1 else 'train'  # Определение train или test        \n",
    "\n",
    "    mode = 'a' if Path(f'input_{name}_Y.txt').exists() else 'w'\n",
    "\n",
    "    with open(f'input_{name}_Y.txt', mode) as f:\n",
    "        for value in diff_data[31:]:\n",
    "            f.write(str(value) + '\\n')\n",
    "\n",
    "\n",
    "# Определяем функцию для записи данных в файл для одной группы\n",
    "def process_group_Y(group):\n",
    "    for i in range(2):\n",
    "        # Добавление столбца с процентной разностью между последовательными значениями столбца 'close'\n",
    "        df_new = group[i].copy()\n",
    "        df_new['close_diff_percent'] = df_new['close'].pct_change() * 100  # Вычисляем процентное изменение\n",
    "        df_new = df_new.dropna()\n",
    "\n",
    "        # Округление значений до четвертого знака после запятой\n",
    "        df_new['close_diff_percent'] = df_new['close_diff_percent'].round(4)\n",
    "\n",
    "        # Запись столбца в файл inputY.txt, начиная с разницы между 32 и 33 элементами\n",
    "        diff_data = df_new['close_diff_percent'].values\n",
    "        # Запись данных в файл\n",
    "        write_data_Y(i, diff_data)\n",
    "\n",
    "for group in tqdm(grouped_data, desc='Processing groups'):\n",
    "    process_group_Y(group)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e27a94c0",
   "metadata": {},
   "source": [
    "### Сравнение доходности"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2913fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаем пустую фигуру\n",
    "fig = go.Figure()\n",
    "\n",
    "# Создаем пустой DataFrame для хранения нормализованных цен\n",
    "normalized_prices = pd.DataFrame()\n",
    "\n",
    "# Проходимся по каждому тикеру\n",
    "for i, group in enumerate(grouped_data):\n",
    "    group_reset = group[1].reset_index(drop=True)\n",
    "\n",
    "    # Находим начальное значение цены\n",
    "    initial_price = group_reset['close'].iloc[0]\n",
    "\n",
    "    # Нормируем цены\n",
    "    normalized_close = group_reset['close'] / initial_price\n",
    "    \n",
    "    # Добавляем нормированные цены в DataFrame\n",
    "    normalized_prices = pd.concat([normalized_prices, normalized_close], axis=1)\n",
    "# Вычисляем среднюю доходность за каждый промежуток\n",
    "average_returns = normalized_prices.mean(axis=1)\n",
    "\n",
    "# Добавляем график средней доходности\n",
    "fig.add_trace(go.Scatter(x=list(range(len(average_returns))), y=average_returns,\n",
    "                         mode='lines',\n",
    "                         name='Средняя доходность',\n",
    "                         line=dict(color='red')))\n",
    "\n",
    "# Загрузка данных из файла\n",
    "with open('avgDailyR.txt', 'r') as file:\n",
    "    lines = file.readlines()\n",
    "    daily_returns = [float(line.strip()) for line in lines]\n",
    "\n",
    "# Вычисление накопленной прибыли\n",
    "cumulative_returns = [1]  # Начальное значение 100, предполагая начальный капитал в размере 100%\n",
    "for daily_return in daily_returns:\n",
    "    cumulative_returns.append(cumulative_returns[-1] * (1 + daily_return / 100))\n",
    "\n",
    "# Добавляем график накопленной прибыли на ту же фигуру\n",
    "fig.add_trace(go.Scatter(x=list(range(len(cumulative_returns))), y=cumulative_returns,\n",
    "                         mode='lines',\n",
    "                         name='Накопленная Прибыль',\n",
    "                         line=dict(color='green')))\n",
    "\n",
    "# Обновляем макет графика\n",
    "fig.update_layout(title='Сравнение средней доходности акций и нашей нейронной сети',\n",
    "                  xaxis_title='Время',\n",
    "                  yaxis_title='Доходность')\n",
    "\n",
    "# Отображаем рисунок с обновленными данными\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
